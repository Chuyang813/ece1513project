{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa116841",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "from surprise import AlgoBase\n",
    "from collections import defaultdict\n",
    "from sentence_transformers import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356891ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD THE REAL BOOK DATA\n",
    "\n",
    "df_books = pd.read_csv(\"Books_df.csv\")\n",
    "\n",
    "# Ensure there's a 'book_id' column\n",
    "if 'book_id' not in df_books.columns:\n",
    "    df_books.insert(0, 'book_id', range(len(df_books)))\n",
    "\n",
    "def create_metadata_text(row):\n",
    "    return (\n",
    "        f\"Title: {row['Title']} | \"\n",
    "        f\"Author: {row['Author']} | \"\n",
    "        f\"Main Genre: {row['Main Genre']} | \"\n",
    "        f\"Sub Genre: {row['Sub Genre']}\"\n",
    "    )\n",
    "df_books['text_for_embedding'] = df_books.apply(create_metadata_text, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "afd94bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE EMBEDDINGS FOR EACH BOOK\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "texts = df_books[\"text_for_embedding\"].tolist()\n",
    "embeddings_tensor = model.encode(texts, convert_to_tensor=True)\n",
    "\n",
    "book_embeddings = {}\n",
    "for idx, row in df_books.iterrows():\n",
    "    b_id = row['book_id']\n",
    "    book_embeddings[b_id] = embeddings_tensor[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0190f615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic Ratings: 63291 total ratings from 20 users.\n"
     ]
    }
   ],
   "source": [
    "# SYNTHETICALLY GENERATE 50 USERS' RATINGS\n",
    "num_users = 20\n",
    "prob_rate = 0.4  # each user has a 40% chance to rate any given book\n",
    "\n",
    "ratings_data = []\n",
    "np.random.seed(42)  # for reproducibility\n",
    "\n",
    "\n",
    "all_book_ids = df_books['book_id'].tolist()\n",
    "\n",
    "for user_id in range(num_users):\n",
    "    for book_id in all_book_ids:\n",
    "        # Decide if this user rates this book\n",
    "        if np.random.rand() < prob_rate:\n",
    "            # random rating from 1..5\n",
    "            rating_val = np.random.randint(1, 6)  # 1 to 5\n",
    "            ratings_data.append((user_id, book_id, rating_val))\n",
    "\n",
    "df_ratings = pd.DataFrame(ratings_data, columns=[\"user_id\", \"book_id\", \"rating\"])\n",
    "print(f\"Synthetic Ratings: {df_ratings.shape[0]} total ratings from {num_users} users.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6f9a0331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE A SURPRISE DATASET\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(df_ratings[[\"user_id\", \"book_id\", \"rating\"]], reader)\n",
    "\n",
    "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4fe25863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE A CUSTOM EMBEDDING-BASED ALGO\n",
    "class EmbeddingBased(AlgoBase):\n",
    "    def __init__(self, book_embeddings, k=10):\n",
    "        AlgoBase.__init__(self)\n",
    "        self.book_embeddings = book_embeddings\n",
    "        self.k = k\n",
    "    \n",
    "    def fit(self, trainset):\n",
    "        super().fit(trainset)\n",
    "        return self\n",
    "    \n",
    "    def estimate(self, u, i):\n",
    "        # Convert internal IDs to raw IDs\n",
    "        try:\n",
    "            user_id = self.trainset.to_raw_uid(u)\n",
    "        except ValueError:\n",
    "            return self.trainset.global_mean\n",
    "        \n",
    "        try:\n",
    "            book_id = self.trainset.to_raw_iid(i)\n",
    "        except ValueError:\n",
    "            return self.trainset.global_mean\n",
    "        \n",
    "        # If no embedding for this book => cold start fallback\n",
    "        if book_id not in self.book_embeddings:\n",
    "            return self.trainset.global_mean\n",
    "        \n",
    "        # Gather user's rated items\n",
    "        user_ratings = self.trainset.ur[u]  # list of (inner_item_id, rating)\n",
    "        if not user_ratings:\n",
    "            return self.trainset.global_mean\n",
    "        \n",
    "        target_emb = self.book_embeddings[book_id]\n",
    "        \n",
    "        scores_sims = []\n",
    "        for (j_inner, rating_j) in user_ratings:\n",
    "            j_raw = self.trainset.to_raw_iid(j_inner)\n",
    "            if j_raw in self.book_embeddings:\n",
    "                j_emb = self.book_embeddings[j_raw]\n",
    "                sim_val = float(util.cos_sim(target_emb, j_emb)[0][0])\n",
    "                scores_sims.append((rating_j, sim_val))\n",
    "        \n",
    "        if not scores_sims:\n",
    "            return self.trainset.global_mean\n",
    "        \n",
    "        # Sort by similarity descending\n",
    "        scores_sims.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_k = scores_sims[: self.k]\n",
    "        \n",
    "        numerator = sum(r * s for (r, s) in top_k)\n",
    "        denominator = sum(s for (_, s) in top_k)\n",
    "        \n",
    "        if denominator == 0:\n",
    "            return self.trainset.global_mean\n",
    "        return numerator / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "71874c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.4743\n"
     ]
    }
   ],
   "source": [
    "algo_llm = EmbeddingBased(book_embeddings, k=10)\n",
    "algo_llm.fit(trainset)\n",
    "predictions_llm = algo_llm.test(testset)\n",
    "rmse_llm = accuracy.rmse(predictions_llm, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8ec8d69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall(predictions, k=10, threshold=3.5):\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((iid, est, true_r))\n",
    "    \n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    \n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "        # Sort by estimated rating descending\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # number of relevant items\n",
    "        n_rel = sum((true_r >= threshold) for (_, _, true_r) in user_ratings)\n",
    "        \n",
    "        # number of recommended items in top k that are relevant\n",
    "        n_rec_k = sum((true_r >= threshold) for (_, _, true_r) in user_ratings[:k])\n",
    "        \n",
    "        precision = n_rec_k / k if k > 0 else 1\n",
    "        recall = n_rec_k / n_rel if n_rel != 0 else 1\n",
    "        \n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "    \n",
    "    mean_precision = np.mean(precisions)\n",
    "    mean_recall = np.mean(recalls)\n",
    "    return mean_precision, mean_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "80f06b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision@10: 0.4050, Recall@10: 0.0162\n"
     ]
    }
   ],
   "source": [
    "p_llm, r_llm = precision_recall(predictions_llm, k=10, threshold=3.5)\n",
    "print(f\"\\nPrecision@10: {p_llm:.4f}, Recall@10: {r_llm:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
